# 운영체제

깃을 보자. 시간남으면 블로그 글, 반효경 교수님 강의 듣기

# 반효경 교수님 강의 정리

[반효경 교수님 강의 정리](https://www.notion.so/b6865da08f42467c9a28f5e11cd0204d)

# 공룡책

[Chapter 1](https://www.notion.so/Chapter-1-18403eba1ee54dce9f67e2e2e2b182dd)

# 깃

## 운영체제란

하드웨어를 관리하고 응용프로그램과 하드웨어 사이에서 인터페이스 역할을 하며 시스템의 동작을 제어하는 시스템 소프트웨어

**운영체제는 시스템의 자원과 동작을 관리하는 소프트웨어이다.**

(시스템의 역할 구분에 따라 운영체제의 역할은 모두 다를 수 있다.)

운영체제를 큰 틀로 나눠보면 다음과 같다.

1. 프로세스 관리
- 프로세스, 스레드
- 스케줄링
- 동기화
- IPC 통신

1. 저장장치 관리
- 메모리 관리
- 가상 메모리
- 파일 시스템

1. 네트워킹
- TCP/IP
- 기타 프로토콜

1. 사용자 관리
- 계정 관리
- 접근권한 관리

1. 디바이스 드라이버
- 순차접근 장치
- 임의접근 장치
- 네트워크 장치

### 프로세스 관리

운영체제에서 작동하는 응용 프로그램을 관리하는 기능이다.

어떤 의미에서는 프로세서(CPU) 관리하는 것이라고 볼 수도 있다. 현재 CPU를 점유해야할 프로세스를 결정하고 실제로 CPU를 프로세스에 할당하며, 이 프로세스 간 공유 자원 접근과 통신 등을 관리하게 된다.

- 프로세스 스케줄링 및 동기화 관리 담당
- 프로세스 생성과 제거, 시작과 정지, 메시지 전달 등의 기능 담당

### 저장장치 관리

1차 저장장치에 해당하는 메인 메모리와 2차 저장장치에 해당되는 하드디스크, NAND 등을 관리하는 기능이다.

- 1차 저장장치(메인 메모리)
    - 프로세스에 할당하는 메모리 영역의 할당과 해제
    - 각 메모리 영역 간의 침범 방지
    - 메인 메모리의 효율적 활용을 위한 가상 메모리 기능
- 2차 저장장치(HDD, NAND Flash Memory 등)
    - 파일 형식의 데이터 저장
    - 이런 파일 데이터 관리를 위한 파일 시스템을 OS에서 관리
    - FAT, NFTS, EXT2, JFS, XFS 등 많은 파일 시스템들이 개발되어 사용 중

### 네트워킹

네트워킹은 컴퓨터 활용의 핵심과도 같아졌다.

TCP/IP 기반의 인터넷에 연결하거나, 응용 프로그램이 네트워크를 사용하려면 **운영체제에서 네트워크 프로토콜을 지원해야 한다.** 현재 상용 OS들은 다양하고 많은 네트워크 프로토콜을 지원한다.

이처럼 운영체제는 사용자와 컴퓨터 하드웨어 사이에 위치해서, 하드웨어를 운영 및 관리하고 명령어를 제어하여 응용 프로그램 및 하드웨어를 소프트웨어적으로 제어 및 관리를 해야한다.

### 사용자 관리

우리가 사용하는 PC는 오직 한 사람만의 것일까?아니다

하나의 PC로도 여러 사람이 사용하는 경우가 많다. 그래서 운영체제는 한 컴퓨터를 여러 사람이 사용하는 환경도 지원해야 한다. 가족들이 각자의 계정을 만들어 PC를 사용한다면, 이는 하나의 컴퓨터를 여러 명이 사용한다고 말할 수 있다.

따라서, 운영체제는 각 계정을 관리할 수 있는 기능이 필요하다. 사용자 별로 프라이버시와 보안을 위해 개인 파일에 대해선 다른 사용자가 접근할 수 없도록 해야 한다. 이 밖에도 파일이나 시스템 자원에 접근 권한을 지정할 수 있도록 지원하는 것이 사용자 관리 기능이다.

### 디바이스 드라이버

운영체제는 시스템의 자원, 하드웨어를 관리한다. 시스템에는 여러 하드웨어가 붙어 있는데, 이들을 운영체제에서 인식하고 관리하게 만들어 응용 프로그램이 하드웨어를 사용할 수 있게 만들어야 한다.

따라서, 운영체제 안에 하드웨어를 추상화 해주는 계층이 필요하다. 이 계층이 바로 디바이스 드라이버라고 불린다. 하드웨어의 종류가 많은 만큼, 운영체제 내부의 디바이스 드라이버도 많이 존재한다.

이러한 수많은 디바이스 드라이버들을 관리하는 기능 또한 운영체제가 맡고 있다.

# 부팅이 되는 과정

[https://neos518.tistory.com/113](https://neos518.tistory.com/113)

# 커널이란?

컴퓨터와 전원을 키면 운영체제는 이와 동시에 수행된다. 한편 소프트웨어가 컴퓨터 시스템에서 수행되기 위해서는 메모리에 그 프로그램이 올라가 있어야 한다. 마찬가지로 운영체제 자체도 소프트웨어로서 전원이 켜짐과 동시에 메모리에 올라가야 한다. 하지만, 운영체제처럼 규모가 큰 프로그램이 모두 메모리에 올라간다면 한정된 메모리 공간의 낭비가 심할 것이다. 따라서 운영체제 중 **항상 필요한 부분**만을 전원이 켜짐과 동시에 메모리에 올려놓고 그렇지 않은 부분은 필요할 때 메모리에 올려서 사용하게 된다. 이 때 **메모리에 상주하는 운영체제의 부분을 커널**이라고 한다. 이것을 좁은 의미의 운영체제라고도 한다. 즉 커널은 메모리에 상주하는 부분으로써 운영체제의 핵심적인 부분을 뜻한다. 이에 반에 넓은 의미의 운영체제는 커널뿐 아니라 각종 시스템을 위한 유틸리티들을 광범위하게 포함하는 개념이다. (보통은 운영체제라고 하면 커널을 말하게 된다)

[https://goodmilktea.tistory.com/23](https://goodmilktea.tistory.com/23)

# 프로세스의 5가지 상태

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled.png)

1. 생성 : 프로세스 생성 상태, pcb를 할당받은 상태
2. 준비 : 프로세스가 cpu에 할당되기를 기다리는 상태
3. 대기 : 보류라고도 하며, 프로세스가 입출력이나 이벤트를 기다리는 상태
4. 실행 : 프로세스가 cpu에 할당되어 실행중인 상태
5. 종료 : 프로세스 종료 상태

### 상태 전이

승인(Admitted): 프로세스 생성이 가능하여 승인됨.

스케줄러 디스패치 : 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것.

인터럽트 : 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것

입출력 또는 이벤트 대기 : 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것

입출력 또는 이벤트 완료: 입출력/이벤트가 끝난 프로세스를 준비 상태로 전황하여 스케줄러에 의해 선택될 수 있도록 만드는 것

[https://rebas.kr/852](https://rebas.kr/852)

# 메모리 계층 구조

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%201.png)

메모리들은 프로그램이 실행하는 동안 데이터의 입력 및 출력을 담당한다.

### 메모리 종류

1. 메인 메모리: 램(RAM)
2. 레지스터 : cpu안에 내장되어 있어 연산을 위한 저장소 제공
3. 캐시 : cpu와 RAM 사이에서 중간 저장소 역할
4. 하드 디스크와 이외 장치 : 하드디스크, I/O장치 등 (CPU와 거리가 가까울수록 빠르고 용량이 작다. 멀수록 느리고 용량이 크다.)

### 데이터 이동

- 프로그램의 실행을 위해 하드디스크에 있는 내용은 메인 메모리로 이동한다.
- 메인 메모리에 있는 일부 데이터도 실행을 위해 L2 캐시로 이동한다.
- L2 캐시에 있는 데이터 일부는 L1캐시로 이동한다.
- L1캐시에 있는 데이터 중 연산이 필요한 데이터는 레지스터로 이동한다.

반대로 연산에 필요한 데이터가 레지스터에 없으면 L1캐시를 살펴본다. 없으면 L2캐시 없으면 메인 메모리, 그래도 없으면 하드디스크를 참조한다. 하드디스크에서 데이터를 찾은 후 다시 메인 메모리, L2캐시,L1캐시를 거쳐 레지스터로 데이터가 들어오게 되는데 이경우 극심한 속도저하가 발생한다.

(참고: 캐시를 없애 중간단계를 줄이는 것이 속도가 빠르지 않냐 생각할 수 있는데 L1캐시와 L2 캐시에 연산에 필요한 데이터가 존재할 확률이 90%이상이다. 따라서 캐시는 속도 향상에 도움을 준다.)

L1캐시와 L2캐시:

시스템의 성능을 좌우하는 클럭속도는 느린쪽에 맞춰진다.

CPU는 고속화되었지만 메인 메모리의 처리속도는 이를 따라가지 못한다.

CPU가 연산을 하기 위해선 데이터를 가지고 와서 연산을 한 후 연산결과를 메모리에 저장한 후에 다음 작업을 수행할 수 있다.

따라서 아무리 CPU가 빠르게 연산을 수행한다 하더라도 데이터를 가져오고 저장하는 작업이 느리다면 전체적인 처리속도는 결코 빠를 수 없다.

L1캐시는 이러한 레지스터와 메인 메모리 간의 속도차이에 의한 성능저하를 막기 위해 메인 메모리의 저장된 데이터 중 자주 접근하는 데이터를 저장한다.

L1 캐시는 CPU 내부에 존재하므로 L1캐시에서 데이터를 참조할 경우 속도저하는 발생하지 않는다. 하지만 여전히 L1캐시는 메인 메모리의 모든 데이터를 저장할 수 없기에 L1캐시에 없는 데이터를 CPU가 요구할 경우 속도의 저하로 이어진다.

따라서 캐시를 하나 더 둔다.(L1 캐시에 용량을 증가시키는데에도 한계가 있다 ⇒ 돈과 기술)

L2캐시까지 존재함으로써 메인 메모리에 대한 접근은 더욱 줄어든다.

따라서 병목현상은 L1캐시와 메인 메모리에서 L2 캐시와 메인 메모리로 발생지역이 옮겨지게 된다.

캐시와 캐시 알고리즘 :

템퍼럴 로컬리티: 한번 접근이 이뤄진 주소의 메모리 영역은 자주 접근한다.

스페이셜 로컬리티: 접근하는 메모리 영역은 이미 접근이 이루어진 영역의 근처일 확률이 높다.

캐시 프렌드리 코드: 템퍼럴 로컬리티와 스페이셜 로컬리티를 최대한 활용하여 캐시의 도움을 받을 수 있도록 구현한 코드

캐시 알고리즘:

캐시 힛: 연산에 필요한 데이터가 L1 캐시에 존재할 경우

캐시 미스: 연산에 필요한 데이터가 L1캐시에 존재하지 않을 경우

(이경우 L2 캐시를 검사하며 L2 캐시미스가 발생하면 메인메모리에서 데이터를 가져온다.)

데이터의 이동은 블록 단위로 진행하여 스페이셜 로컬리티의 특성을 성능향상에 활용한다.

(예: 0x10000 번지의 데이터를 요청하면 0x10000을 포함한 블록 전체가 전송된다.)

메모리 계층 아래로 갈수록 전송되는 블록 크기가 커진다.

아래에 존재하는 메모리에 대한 접근 횟수를 줄여준다.

캐시 교체 정책:

프로그램이 실행되는 동안 모든 메모리는 항상 채워져있다.

메모리가 꽉 채워져 있어야 요구하는 데이터를 가지고 있을 확률이 높아지기 때문이다.

이 때문에 가지고 있지 않은 데이터를 요구할 경우 메모리가 꽉 찼기 때문에 메모리 블록을 교체해야한다.

블록 교체 알고리즘은 캐시 교체 정책에 의해 달라진다.

(대표적 블록 교체 알고리즘 : LRU ⇒ 가장 오래전에 참조된 블록을 밀어내는 알고리즘)

[https://dakuo.tistory.com/126](https://dakuo.tistory.com/126)

# CPU 스케줄링

### FCFS(First Come First Served, 선입선출)

먼저 CPU를 사용하기 위해 도착한 프로세스를 먼저 처리해주는 방식을 말한다. 이는 일상생활에서 줄서기하는 것과 같다. 이 방법을 사용하면 먼저 CPU를 요청한 프로세스가 작업이 끝날 때까지 다른 프로세스들은 작업을 할 수 없다. CPU는 효율적으로 계속 작업을 할 수 있으나 전체적인 프로세스를 처리하는 면에서는 비효율적이다.

### RR(Round Robin, 라운드 로빈)

선입선출의 방법을 보완하고자 나온 방법이 라운드 로빈 스케줄링이다. 이 기법에서는 CPU를 한 번 할당받아 사용할 수 있는 시간을 일정한 고정된 시간으로 제한한다. 긴 작업이 필요한 프로세스가 CPU를 할당받더라도 정해진 시간이 지나면 CPU를 내어놓고 CPU의 서비스를 기다리는 줄의 제일 뒤에서 기다려야 한다. 이렇게 되면 뒤의 프로세스들이 무작정 오래 기다려야 하는 상황은 막을 수 있다.

### 우선순위(Priority)

이 기법은 수행 대기중인 프로세스들에게 프로그램에 따라 우선순위를 부여하고 우선순위가 높은 프로세스에게 CPU를 먼저 할당하게 된다. 또한 지나치게 오래 기다리는 프로세스가 발생하지 않도록 기다린 시간이 늘어날수록 우선순위를 점차 높여주는 방안도 사용될 수 있다.

[https://goodmilktea.tistory.com/23](https://goodmilktea.tistory.com/23)

# 메모리 관리

### 고정 분할

물리적 메모리를 몇개의 영구적인 분할로 나눈다. 나뉜 각각의 분할에는 하나의 프로그램이 적재된다. 이 방식은 단순해서 분할의 크기보다 큰 프로그램은 적재가 불가능하다. 이렇기 때문에 메모리의 효율적인 사용 측면에서도 바람직하지 않다.

### 가변 분할

매 시점 프로그램의 크기에 맞게 메모리를 분할해서 사용하는 방식이다. 따라서 분할보다 큰 프로그램의 실행이 제한되는 문제는 발생하지 않는다. 그러나 물리적 메모리 크기보다 더 큰 프로그램의 실행은 여전히 불가능하다.

### 가상 메모리

최근에 거의 모든 컴퓨터 시스템에서 사용하는 메모리 관리 기법이다. 가상 메모리 기법에서는 물리적 메모리보다 더 큰 프로그램이 실행되는 것을 지원한다. 이 때 실행될 수 있는 프로그램의 크기는 가상 메모리의 크기에 의해 결정된다. 운영체제는 물리적인 주소와 가상 메모리에 주소를 매핑하여 관리한다. 실제 이렇게 가상 메모리를 할당할 수 있게 하는 것은 실행되지 않는 부분의 프로그램은 보조디스크에 두었다가 필요할 때 메모리에 적재하는 방식이다. 그리고 이때 보조 기억장치에서 사용되는 부분을 스왑영역이라고 한다.

[https://goodmilktea.tistory.com/23](https://goodmilktea.tistory.com/23)

# 주변 장치 및 입출력 장치 관리

CPU나 메모리와 달리 인터럽트라는 메커니즘을 통해 관리한다. 주변 장치들은 CPU의 서비스가 필요한 경우에 신호를 발생시켜 서비스를 요청하게 되는데 이 때 발생시키는 신호를 인터럽트라고 한다. CPU는 평소에 CPU 스케줄링에 따라 자신에게 주어진 작업을 수행하고 있다가 인터럽트가 발생하면 하던 일을 잠시 멈추고 인터럽트에 의한 요청 서비스를 수행하게 된다.

주변 장치들은 각 장치마다 그 장치에서 일어나는 업무에 대한 관리를 위해 일종의 작은 CPU를 가진다. 이를 컨트롤러라고 하는데 이 컨트롤러를 바탕으로 무언가 입력이 되면 CPU에게 인터럽트를 발생시켜 보고하는 역할을 한다. 그러면 CPU는 하던 일을 잠시 멈추고 인터럽트에 대한 처리를 하기위해 운영체제로 할당이 넘어간다.

[https://goodmilktea.tistory.com/23](https://goodmilktea.tistory.com/23)

# 캐시와 버퍼의 차이점

### 캐시

- 이전에 접근한 데이터를 빠르게 접근하기 위해 임시로 저장
- 교체 알고리즘에 따라 삭제될수도 안될수도 있다.
- 캐시는 어떤 원리로 저장되나요? 지역성 / (시간,공간)
    - 한 번 참조되면 가까운 미래에 또 사용될 수 있다.
    - 참조된 메모리에 가까운 곳에 있는 데이터가 또 사용될 수 있다.

### 버퍼

- 전송 전에 임시로 저장
- 미리 출력할 것을 버퍼에 담아서 성능 빠르게
- 사용후에 바로 삭제한다.

# 메모리 단편화, 페이징, 세그멘테이션

### 메모리 단편화

메모리의 공간이 작은 조각으로 나뉘어져서 **사용가능한 메모리가 충분히 존재하지만 할당(사용)이 불가능한 상태**

### 외부 단편화

메모리가 할당되고 해제되는 작업이 반복되면서 작은 메모리가 중간중간에 존재

이 때 중간에 생긴 사용하지 않은 메모리가 많이 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황

### 내부 단편화

**프로세스가 필요한 양보다 더 큰 메모리가 할당 되어서** 프로세스에서 사용하는 메모리가 낭비되는 

상황

### 메모리 단편화 문제 해결 방법

### 1. 페이징 기법

- **가상메모리**를 같은 크기의 블록으로 나눈 것을 **페이지** 라고 하고 **물리메모리**를 페이지와 같은 크기로 나눈 것을 **프레임**이라고 할때,
- 페이징 기법이란 사용하지 않는 프레임을 페이지에 옮기고, 필요한 메모리를 페이지 단위로 프레임에 옮기는 기법.
- 페이지와 프레임을 대응시키기 위해 페이지 매핑 과정이 필요해서 페이징 테이블을 만든다.
- 방법 : 프로세스를 페이지 단위로 나눈 뒤에, 사용하지 않는 영역을 보조기억장치에 적재한다. 이를 페이징 되었다고 하는데, 만약 이 페이징 된 영역에 접근해야 하면 페이징 폴트를 발생시킨 후 메모리에 적재시킨다.(요구 페이징) 페이징된 정보는 페이징 테이블에 저장된다.
- 장점 : 연속적이지 않은 공간도 활용할 수 있기 때문에 외부 단편화 문제를 해결할 수 있다.
- 단점 : 페이지 단위에 알맞게 꽉 채워 쓰는 게 아니므로 내부 단편화 문제는 여전히 있다.
- 페이지 단위를 작게하면 내부 단편화 문제도 해결할 수 있겠지만 대신 페이지 매핑 과정이 많아지므로 오히려 효율이 떨어질 수 있다.
- 외부 단편화 해결, 내부 단편화 존재

### 페이징 테이블

페이징 기법에서 사용되는 자료구조로서, **프로세스의 페이지 정보를 저장**하고 있는 테이블이다.

### 세그멘테이션 기법

- 가상메모리를 **서로 크기가 다른 논리적 단위인 세그먼트로 분할해서 메모리를 할당**하여 실제 메모리 주소로 변환을 하게 된다.
- 각 세그먼트는 **연속적인 공간에 저장**되어 있다.
- 세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈공간을 찾아 할당하는 기법
- 마찬가지로 매핑을 위해 세그먼트 테이블이 필요하다.(각 세그먼트 항목별 세그먼트 시작주소와 세그먼트의 길이 정보를 가지고 있다.)
- 프로세스가 필요한 메모리 만큼 할당해주기 때문에 내부 단편화는 일어나지 않으나 여전히 중간에 프로세스가 메모리를 해제하면 생기는 구멍, 즉 외부 단편화 문제는 여전히 존재한다.
- 내부 단편화 해결, 외부 단편화 존재

[https://jeong-pro.tistory.com/91](https://jeong-pro.tistory.com/91)

# 선점 스케줄링과 비선점 스케줄링

### 선점 알고리즘: 어떤 프로세스가 CPU를 할당 받아 실행중이더라도 OS가 CPU를 강제로 빼앗을 수 있다.

- RR(Round Robin): 할당받은 시간(타임 슬라이스)동안 작업하다가 작업 미완료시 준비 큐의 맨 뒤로 간다.
- SRT(Shortest Remaining Time) : SJF+RR 방식
    - 최소 잔류 시간 우선 스케줄링
    - 남은 시간이 적은 프로세스에 CPU를 먼저 할당
- 다단계 큐 스케줄링
    - 우선순위에 따라 준비 큐가 여러개
    - 상단의 큐에 있는 모든 프로세스가 종료되야 다음 우선순위 큐의 작업이 시작된다.
- 다단계 피드백 큐 스케줄링
    - 우선순위가 낮은 프로세스에 불리한 다단계 큐 스케줄링을 보완한 방식
    - CPU를 사용하고 난 프로세스는 원래 큐로 돌아가지 않고, 우선순위가 하나 낮은 큐의 끝으로 들어간다.
    - 우선순위를 낮춤으로써, 다단계 큐에서 우선순위가 낮은 프로세스의 실행이 연기되는 문제를 완화한다.

### 비선점 알고리즘

- FCFS
- SJF(Shortest Job First): 실행 시간이 가장 짧은 작업부터
- HRN(Highest Response Ratio Next): 최고 응답률 우선 스케줄링

### 둘 다 가능

- 우선순위 스케줄링
    - 프로세스는 중요도에 따라 우선순위를 갖는다.
    - 일정 시간마다 우선순위가 변하거나 고정되거나

# 문맥교환(컨텍스트 스위칭)

- CPU를 차지하던 프로세스가 나가고 새로운 프로세스를 받아들이는 작업
- 두 프로세스의 PCB를 교환하는 작업
- 현재까지의 작업 상태를 저장하고 다음 작업에 필요한 각종 상태, 데이터를 읽어오는 작업
- 멀티 프로세스 환경에서 CPU 스케줄러가 인터럽트 발생 시 현재 프로세스의 상태를 PCB에 저장하고, 새로운 프로세스의 상태를 레지스터에 저장하는 것을 말한다.
- 인터럽트의 종류
    - 입출력 요청
    - CPU 사용시간 만료
    - 자식 프로세스 생성
    - 인터럽트 처리 대기
- 컨텍스트 스위칭 시 CPU는 아무런 작업을 하지 못한다. 따라서 잦은 컨텍스트 스위칭은 성능 저하를 일으킨다.

# PCB(프로세스 제어 블록)란?

- **프로세스를 실행하는 데 필요한 중요한 정보를 보관하는 자료구조**
- **각 프로세스가 생성될 때마다 고유한 PCB가 생성되고, 완료되면 제거된다.**
- 프로세스는 CPU를 할당받아 작업을 처리하다가, CPU를 선점당하게 되면 진행 중이던 작업 내용을 PCB에 저장하고 CPU를 반환한다. 이후에 다시 CPU를 할당받으면 PCB로부터 진행이 끊겼던 부분에서 다시 작업을 실행한다. 프로세스 식별자, 상태, PC(프로그램 카운터, 다음 실행할 명령의 주소 가르킴), 매모리 관리 정보 등을 가지고 있다.

# 가상 메모리란?

실제 시스템에 있는 물리적인 메모리의 크기에 상관 없이 가상 공간을 프로세스에게 제공한다. 이런 가상 메모리는 프로세스 전체가 메모리에 적재되지 않아도 프로세스의 실행이 가능하도록 한다.

가상 메모리 어떻게 구현하나요? 페이징, 세그먼테이션

[https://ko.wikipedia.org/wiki/가상_메모리](https://ko.wikipedia.org/wiki/%EA%B0%80%EC%83%81_%EB%A9%94%EB%AA%A8%EB%A6%AC)

[https://twinw.tistory.com/106?category=543743](https://twinw.tistory.com/106?category=543743)

# 데드락(교착 상태)

데드락이란 두 개 이상의 작업이 **서로 상대방의 작업이 끝나기만을 기다리고** 있기 때문에 결과적으로 아무것도 완료되지 못하는 상태를 말한다.

멀티프로세스나 멀티쓰레드 환경에서 **여러 프로세스들이 한정된 자원을 사용**하기 때문에 발생할 수 있다.

### 데드락 발생 조건

모두 충족해야 발생한다.

1. 상호배제: 자원은 한 번에 한 프로세스만이 사용할 수 있다.
2. 점유 대기: 자원을 할당받은 상태에서 다른 자원을 기다리는 상태
3. 비선점: 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 뺏을 수 없다.
4. 순환 대기: 점유와 대기를 하는 프로세스 간의 관계가 원을 이룬다, 그렇게 되면, 프로세스들이 서로 양보하지 않기 때문에 교착상태 발생한다.

### 데드락 처리 1. 예방

- 교착 상태 발생 조건 중 하나를 제거함으로써 해결
    1. 상호배제 부정: 여러 개의 프로세스가 공유 자원 사용 가능하게 한다.(보호해야할 자원을 공유하기 힘들다)
    2. 점유 대기 부정: 프로세스가 실행 되기 전 필요한 모든 자원을 할당한다.(전부 할당 또는 아예 할당x)
    3. 비선점 부정: 자원을 빼앗을 수 있도록 만든다(우선순위가 낮은 프로세스 기아현상)
    4. 순환대기 부정: 모든 자원에 숫자를 부여하고 숫자가 큰 방향으로만 자원할당(번호 부여 방식 선정이 어려움)
- 문제점: 1,3은 자원보호가 힘들고 2,4는 프로세스 작업 방식을 제한하고 자원을 낭비하게 된다.

### 데드락 처리 2.회피

- 교착 상태가 발생하면 피하는 방법
- 교착 상태가 발생하지 않는 범위 내에서만 자원할당, 교착 상태 발생하는 범위에서 프로세스 대기
- 교착 상태 예방보다 좀 더 유연하다

**은행원 알고리즘**

- 은행이 대출 해주는 방식. 즉, 대출 금액이 대출 가능한 범위(안정 상태)면 허용, 그렇지 않으면 거부
- 안정 상태에 있으면 자원을 할당하고, 그렇지 않으면 다른 프로세스들이 자원을 해지할 때까지 대기함

### 데드락 처리 3.탐지

- os가 프로세스의 작업을 관찰하면서 데드락 발생 여부를 계속 주시

**자원 할당 그래프**

- 자원할당 그래프를 통해 프로세스가 어떤 자원을 사용, 기다리는지 알 수 있다.
- 장점: 프로세스의 작업 방식을 제한하지 않으면서 교착상태를 정확하게 파악
- 단점: 자원할당 그래프르 유지, 갱신, 사이클 검수하면서 **오버헤드가 발생**
    - 추가 작업을 줄이기 위해 자원 할당시마다 사이클 검사 안하고 일정시간마다 검사하는 방법도 있다.

**타임아웃**

- 일정 시간 동안 작업이 진행되지 않은 프로세스를 데드락 발생한 것으로 간주하여 처리
- 자원 할당 그래프를 이용하는 것보다 쉽기 때문에 선호한다.

### 데드락 처리 4. 회복

- 데드락 발생 시킨 프로세스를 종료하거나 할당된 자원을 해제하여 회복하는 것을 의미
1. 교착 상태 발생시킨 프로세스 동시에 종료
2. 교착상태 발생시킨 프로세스 중 하나를 골라 순서대로 종료
    1. 우선순위 낮은 프로세스 종료
    2. 작업 시간 짧은 프로세스 종료
    3. 자원을 많이 사용하는 프로세스 종료

 

[https://jwprogramming.tistory.com/12](https://jwprogramming.tistory.com/12)

# 프로세스의 메모리 구조

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%202.png)

메모리 영역은 크게 두가지로 나눌 수 있는데 컴파일 시 크기가 고정되는 code,data,bss 영역과 실행시 메모리가 할당되었다가 반납되는 heap,stack 영역으로 나눌 수 있다.

### 메모리 할당이 고정되는 영역(컴파일 시 결정)

- code 영역
    - 실행 파일을 구성하는 명령어들이 올라가는 메모리 영역으로 함수, 제어문, 상수 등이 여기에 지정된다.
- data & bss 영역
    - data영역은 BSS와 함께 묶어서 데이터 영역으로 칭하기도 하는데 이는 전역변수와 static 변수가 지정되는 영역이다.
    - 초기화 되지 않은 전역변수들은 BSS에 지정된다.

### 실행중에 메모리를 할당하는 영역(할당과 반납이 이루어진다)

- HEAP
    - malloc(), calloc() 등으로 프로그래머가 자율적으로 메모리 크기를 할당할 수 있는 영역이다.
    - 위의 함수들은 free()함수로 할당된 영역을 반납 해줘야 하므로 동적할당 영역에 속한다.
- STACK
    - 지역변수가 할당되는 영역으로 함수가 호출되면 할당되었다가 함수의 종료시 반납되는 영역이다.

위의 힙과 스택은 사실 같은 공간을 공유한다. HEAP이 메모리 위쪽 주소부터 할당되면  STACK은 아래쪽부터 할당되는 식이다. 그래서 각 영역이 상대 공간을 침범하는 일이 발생할 수 있는데 이를 각각 HEAP OVERFLOW, STACK OVERFLOW라고 한다.

[https://zapiro.tistory.com/entry/함수와-메모리-영역](https://zapiro.tistory.com/entry/%ED%95%A8%EC%88%98%EC%99%80-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%98%81%EC%97%AD)

# 쓰레싱

**메모리 영역에 접근하게 될때, 메모리에 페이지 부재(페이지 폴트)율이 높은 것**을 의미하며, 심각한 성능 저하를 초래한다.

- 활발하게 사용되는 페이지 집합을 지원해 줄 만큼 프레임이 충분히 할당 받지 못한 프로세스는 페이지 폴트가 발생하게 된다. 이 때, 페이지 교체가 필요하지만 이미 활발히 사용되는 페이지들만으로 이루어져 있으므로 어떤 페이지가 교체되던 바로 다시 페이지 교체가 필요하게 될 것이다. 결과적으로 바로바로 반복해서 페이지 폴트가 발생하며, 교체된 페이지는 또 다시 얼마 지나지 않아 읽어올 필요가 생기게 된다. 이렇게 과도한 페이징 작업을 **쓰레싱**이라고 한다.
- 하드디스크의 입출력이 너무 많아져서 잦은 페이지 부재로 작업이 멈춘 것 같은 상태
- 재료를 창고→도마, 도마→창고 옮기는 작업이 많아 요리를 못하는 상태

### 쓰레싱의 원인

1. 다중 프로그래밍 정도가 높아짐에 따라 CPU 이용률이 높아지게 되고, CPU 이용률이 최대값에 도달했을 때, 다중 프로그래밍의 정도가 그 이상으로 커지게 되면 쓰레싱이 일어나게 되고 CPU 이용률은 급격히 떨어진다.
2. 운영체제는 CPU 이용률을 감시하며, CPU 이용률이 너무 낮아지면 새로운 프로세스를 시스템에 추가하여 다중 프로그래밍의 정도를 높이게 된다. 이 때 전역 페이지 교체 알고리즘을 사용하여 어떤 프로세스의 페이지인지에 대한 고려없이 교체를 수행하게 된다. 그런데, 교체된 페이지들이 해당 프로세스에서 필요로 하는 것이었다면 그 프로세스 역시 페이지 폴트를 발생시키고 또 다른 프로세스에서 프레임을 가져온다.
3. 이러한 프로세스들이 페이지 스왑 인, 스왑 아웃을 위해 페이징 장치를 사용해야 하는데, 이 장치에 대한 queueing이 진행되며 ready-queue는 비게 된다.
4. 프로세스들이 페이징 장치를 기다리는 동안 CPU 이용률은 떨어지게 되고, CPU 스케줄러는 이용률이 떨어지는 것을 보고 높이기 위해 새로운 프로세스를 추가하여 다중 프로그래밍의 정도를 더 높인다.
5. 새로 시작하는 프로세스는 실행중인 프로세스들로부터 프레임을 가져오고자 하며, 더 많은 페이지 폴트와 더 긴 페이징 대기시간을 야기하게 된다.
6. 결과적으로 CPU  이용률은 더 떨어지고, CPU 스케줄러는 다중 프로그래밍의 정도를 더 높이려 하여 쓰레싱이 일어나게 된다. 따라서 시스템 처리율은 상당히 낮아지고 페이지 폴트는 늘게되어 실질적인 메모리에 접근하는 시간은 증가하고 프로세스들은 페이징 하는데에 시간을 소비하게 되어 아무런 일도 할 수 없는 상태가 된다.

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%203.png)

- 다중 프로그래밍 정도가 높으면 스레싱 발생한다.
- 메모리가 꽉차면 CPU가 작업하는 시간< 스왑영역으로 페이지 보내고, 새로운 페이지 가져오는 작업시간
- CPU가 작업할 수 없는 상태 → 스레싱 발생 지점

### 물리 메모리 크기와 작업 속도

- 물리 메모리 용량을 512MB→4GB로 늘리면 스레싱 발생 지점 늦춰져서 성능 향상
- 물리 메모리 용량을 4GB(물리 메모리가 작업하는 데 충분한 크기)→16GB로 늘리면? 크기를 늘려도 작업 속도에 영향 X

### 스레싱과 프레임 할당

- 남아있는 프레임을 실행중인 프로세스에 적절히 나눠주는 정책
- 프로세스에 너무 적은 프레임 할당 시, 페이지 부재 빈번
- 너무 많은 프레임 할당시, 페이지 부재는 적지만 메모리 낭비 ⇒ 각 프로세스가 필요로 하는 최소한의 프레임 갯수를 보장해줘야 한다.

쓰레싱은 지역교환 알고리즘이나 우선순위 교환 알고리즘을 사용해 제한할 수 있다.

⇒ 지역교환 알고리즘 하에서는 한 프로세스가 쓰레싱을 유발하더라도 다른 프로세스로부터 프레임을 뺏어 올수 없으므로 다른 프로세스는 쓰레싱에서 자유로울 수 있다.

[https://jwprogramming.tistory.com/56](https://jwprogramming.tistory.com/56)

# 프로세스 간 통신하는 방법?

### 프로세스 간 통신(IPC, Inter Process Communication)

- 정의: 하나의 컴퓨터 안에서 실행중인 서로 다른 프로세스 간 발생하는 통신
- 기능 : 의사 소통 기능 & 동기화를 보장해야 한다.
- 동기화: 하나의 프로세스가 공유 데이터 값을 변경하는 동안, 다른 프로세스는 그 데이터에 접근X
- **종류: 메시지 전달 방식, 공유메모리 방식(공유 변수 사용 여부에 따라 나뉜다.)**

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%204.png)

### 1. 메시지 전달 방식

- 특징: IPC를 위해 **커널을 통해** 메세지를 전달하는 방식으로 자원,데이터를 주고받는다.
- 장점: 별도의 구축없이 커널을 이용하기 때문에 비교적 구현이 쉽다.
- 단점: 커널을 이용하기 때문에 시스템 콜이 필요하며 이로 인해 **오버헤드**가 발생
- 종류: **파이프, 메세지 큐, 소켓, 시그널**

### 1-1 메시지 전달 모델 - 파이프

- 특징: 하나의 프로세스가 파이프를 통해 다른 프로세스로 메시지를 직접 전달
- 단점: **단방향 통신,** 따라서 2개의 프로세스 통신시 2개의 파이프가 필요하다. 100개의 프로세스 통신 시 100^2개가 필요하므로 자원낭비가 심하다.
- 종류: 익명파이프, 네임드 파이프
    - 익명 파이프: 사용에 제한이 있다.
        - 이름이 없기 때문에 외부 프로세스에서 이 파이프 호출불가
        - 부모, 자식 프로세스 간 통신시 사용
    - 네임드 파이프: 이름이 있기 때문에 외부 프로세스와 통신 가능

### 1-2 메시지 전달 모델 - 메시지 큐

- 특징: 고정 크기의 메시지를 연결 리스트를 통해 통신하는 방식
- 메시지 단위의 통신, 메시지 큐 id를 통해 통신

### 1-3 메시지 전달 모델 - 소켓

- 특징: 네트워크 상에서 프로세스간 통신, local&remote 통신 가능

### 2. 공유 메모리 방식

- 특징: IPC를 위해 공유 메모리 영역을 구축하고, 공유 영역을 통해 자원이나 데이터를 주고 받는다.
- 장점: 커널 의존성이 낮기 때문에 **속도가 빠르다.** 유저 레벨에서 IPC가 가능하기 때문에 **통신이 자유롭다.**
- 단점: **자원과 데이터를 공유하기 때문에 동기화 이슈** 발생한다.

# 32bit CPU와 64bit CPU의 차이

bit: CPU가 처리하는 데이터의 최소 단위(레지스터)의 크기 - 32bit/64bit CPU는 한 번에 다룰 수 있는 데이터의 크기가 32bit/64bit

- CPU 내부 부품은 비트를 기준으로 제작된다.
    - 32bit CPU 내의 레지스터 크기, 산술 논리 연산장치, 버스의 크기, 대역폭 모두 32bit
- 메모리 주소 레지스터(MAR, 메모리 주소를 지정하는 레지스터) 크기가 32bit 이므로 표현 할 수 있는 메모리 주소의 범위가 0~2의 32승, 총 크기는 2의 32승 bit, 약 4기가이다.

**차이점**

- 32비트 CPU 컴퓨터는 최대 4기가의 메모리까지만 사용 가능하다.
- 64비트 CPU 컴퓨터는 4기가 이상의 메인 메모리를 사용 가능하다.

# 장기/중기/단기 스케줄러

## 프로세스 스케줄링

다중 프로그래밍의 목적은 CPU의 사용률을 최대화 하는 것이다. 여러 개의 프로그램을 메모리에 올려 하나의 프로그램이 입출력 작업을 수행 중인 경우(CPU 연산이 필요하지 않은 경우) CPU가 다른 프로세스를 수행함으로써 CPU가 항상 어떤 프로세스든지 실행중이게 한다는 방법이다. 이것이 가능하기 위해선 시분할이 이루어져야 한다. 시분할은 내용 전환을 하면서 현재 수행할 프로세스를 바꾸는 것인데, 내용 전환을 하기 위해 다음에 어떤 프로세스를 수행할 것인지를 설정하고 관리하는 것이 프로세스 스케줄링(CPU 스케줄링)이다.

**프로세스 스케줄링**: 다중 프로그래밍을 가능하게 하는 운영체제의 동작 기법. 운영체제는 프로세스들에게 CPU등의 자원 배정을 적절히 함으로써 시스템의 성능을 개선할 수 있다.

## 스케줄링 큐

프로세스들은 여러 큐들을 이동하며 스케줄링 된다.

- 작업 큐: 시스템 내에 있는 모든 프로세스 집합
- 준비 큐: 메인 메모리에 상주하면서 실행될 준비를 하고 있는 프로세스 집합
- 장치 큐: 입출력 장치를 기다리고 있는 프로세스 집합

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%205.png)

위 그림처럼 프로세스들은 여러 큐를 이동하면서 스케줄러가 정한 순서에 맞춰서 작업을 수행한다.

## 스케줄러

- 장기 스케줄러: 디스크로부터 메인 메모리 상의 준비 큐로 옮겨질 프로세스들을 선택한다. 하드⇒ 메인 메모리, 호출 빈도 적음
- 단기 스케줄러: 준비 큐에 있는 어떤 프로세스가 다음 차례에 수행될지 선택하여 CPU를 할당한다. 메인 메모리⇒ CPU, 장기 스케줄러에 비해 호출 빈도 많음
- 하드에서 메인 메모리로 로드하는 것은 꽤 느린 편이다. 때문에 장기 스케줄러는 신중히 프로세스를 메인 메모리로 로드해야 한다. 그래서 장기 스케줄러는 입/출력을 많이하는 프로세스와 CPU 연산을 많이 필요로 하는 프로세스 두 가지를 적절히 선택하여 메인 메모리로 로드하는 것이 중요하다.
- 중기 스케줄러: 스와핑을 한다. (사용하지 않는 프로세스들을 제거하여 다중 프로그래밍 정도를 줄이고, 이 프로세스는 후에 다시 메모리로 올라와 수행을 계속할 수 있다.) CPU를 차지하기 위한 경쟁이 심해질 때 우선순위가 낮은 프로세스들을 잠시 제거한 후 나중에 경쟁이 완화되었을 때 다시 디스크에서 메모리로 불러와 중단되었던 부분부터 다시 실행시켜준다.

[https://twinw.tistory.com/4](https://twinw.tistory.com/4)

[https://twinjh.tistory.com/18](https://twinjh.tistory.com/18)

# 프로세스와 쓰레드

## 프로세스

- 실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU의 할당을 받은 작업의 단위이다.
- 운영체제로부터 시스템 자원을 할당받는다.
- 할당받는 시스템 자원
    - CPU 시간
    - 운영되기 위한 주소 공간
    - Code, Data, Stack, Heap의 구조로 되어있는 독립된 메모리 영역
- 기본적으로 프로세스마다 최소 1개의 쓰레드를 갖는다(메인 쓰레드)
- 프로세스는 각각 별도의 메모리 영역(주소 공간)을 할당받는다. [Code, Data, Stack, Heap]
- 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없으며, 접근을 위해서는 IPC 통신이 필요하다. ex)파이프, 파일, 소켓 등을 이용한 통신방법

## 프로세스 제어 블록(PCB)

- 특정 프로세스에 대한 중요한 정보를 저장하고 있는 **커널 내의 자료구조**이다.
- OS는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB를 생성한다.
- 프로세스는 CPU를 할당받아 작업을 처리하다가 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 한다. 이때 작업의 진행 상황을 모두 PCB에 저장한다. 그리고 다시 CPU를 할당받게 되면 PCB에 저장되었던 내용을 불러와 종료되었던 시점부터 다시 작업을 수행한다.
- PCB에 저장되는 정보
    - 프로세스 식별자: 프로세스 식별 번호
    - 프로세스 상태: new, ready, running. waiting, terminated 등의 상태를 저장
    - 프로그램 카운터: 프로세스가 다음에 실행할 명령어의 주소를 가리킨다.
    - CPU 레지스터
    - CPU 스케줄링 정보: 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
    - 메모리 관리 정보: 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함한다.
    - 입출력 상태 정보: 프로세스에 할당된 입출력 장치들과 열린 파일 목록
    - 어카운팅 정보: 사용된 CPU 시간, 시간 제한, 계정 번호 등

## 쓰레드

- 프로세스의 실행 단위라고 할 수 있으며, 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유할 수 있다.

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%206.png)

- 쓰레드는 프로세스 내의 Code, Data, Heap 영역은 다른 스레드와 공유하고 Stack 영역을 따로 할당받는다.
- 여러 쓰레드는 한 프로세스 내의 Code, Data, Heap 영역을 공유하지만 프로세스 간에는 메모리에 접근할 수 없다.
- 쓰레드는 별도의 레지스터와 스택을 갖고 있으며, 다른 영역을 공유한다. 따라서 한 쓰레드가 프로세스의 자원을 변경하면 다른 스레드도 그 변경 결과를 즉시 확인할 수 있다.

## 요약

**프로세스: 자신만의 고유 공간과 자원을 할당받아 사용하는 작업의 단위**

**쓰레드: 프로세스 내에서 실행되는 흐름의 단위로, 다른 스레드와 프로세스의 자원 및 공간을 공유하면서 사용**

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%207.png)

[https://www.youtube.com/watch?v=iks_Xb9DtTM&list=PLpO7kx5DnyIExYt0jkyWWjx8XNA2Fx2rI&index=5](https://www.youtube.com/watch?v=iks_Xb9DtTM&list=PLpO7kx5DnyIExYt0jkyWWjx8XNA2Fx2rI&index=5)

# 멀티 프로세스와 멀티 쓰레드

## 멀티 프로세스

- 두개 이상 다수의 프로세서(CPU)가 협력적으로 하나 이상의 작업(Task)을 동시에 처리하는 것이다.(병렬처리)
- 각 프로세스 간 메모리 구분이 필요하거나 독립된 주소 공간을 가져야 할 경우 사용한다.

### 장점

- 독립된 구조로 안정성이 높다
- 프로세스 중 하나에 문제가 생겨도 다른 프로세스에 영향을 주지 않아 작업속도가 느려지는 손해정도는 생기지만 정지되거나 하는 문제는 발생하지 않는다.
- 여러개의 프로세스가 처리되어야 할 때 동일한 데이터를 사용하고, 이러한 데이터를 하나의 디스크에 두고 모든 프로세서가 이를 공유하면 비용적으로 저렴하다.

### 문제점

- 독립된 메모리 영역이기 때문에 작업량이 많을수록 (내용 전환이 자주 일어나 주소 공간의 공유가 잦을 경우) 오버헤드가 발생하여 성능저하가 생긴다
- 내용 전환 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 시간이 소모되는 등 오버헤드가 발생한다.

## 멀티 쓰레드

- 하나의 프로세스에 여러 스레드로 자원을 공유하며 작업을 나누어 수행하는 것이다.
- 윈도우, 리눅스 등 많은 OS들이 멀티 프로세싱을 지원하고 있지만, 멀티 스레딩을 기본으로 하고있다.
- 웹 서버는 대표적인 멀티 스레드 응용 프로그램이다.

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%208.png)

### 장점

- 시스템 자원소모 감소(자원의 효율성 증대)
    - 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어 자원을 효율적으로 관리할 수 있다.
- 시스템 처리율 향상(처리비용 감소)
    - 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어든다.
    - 스레드 사이 작업량이 작아 문맥 교환이 빠르다(캐시 메모리를 비울 필요가 없다.)
- 간단한 통신 방법으로 프로그램 응답시간 단축
    - 스레드는 프로세스 내 스택영역을 제외한 메모리 영역을 공유하기에 통신 비용이 적다
    - 힙 영역을 공유하므로 데이터를 주고 받을 수 있다.

### 문제점

- 자원을 공유하기에 동기화 문제가 발생할 수 있다.(병목현상, 데드락 등)
- 주의 깊은 설계가 필요하고 디버깅이 어렵다.(불필요 부분까지 동기화 하면, 대기시간으로 인해 성능 저하 발생)
- 하나의 스레드에 문제가 생기면 전체 프로세스가 영향을 받는다.
- 단일 프로세스 시스템의 경우 효과를 기대하기 어렵다.

- 멀티 쓰레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 내용 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 가지고 있다.
- 반면, 멀티 프로세싱 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 있다.
- 이 두가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다.

## 자주 나오는 질문

### 멀티 프로세스 대신 멀티 쓰레드를 사용하는 이유는?

![Untitled](%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%209de93c6895dd43d19f30e7f0b3e7c62e/Untitled%209.png)

- 프로그램을 여러개 키는 것보다 하나의 프로그램 안에서 여러 작업을 해결하는 것이 더욱 효율적이기 때문이다.
- **프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다.**
- 내용 전환시, 캐시 메모리를 비울 필요가 없기 때문에 비용이 적고 더 빠르다.⇒쓰레드는 스택영역만 초기화하면 되기 때문이다.
- 쓰레드는 프로세스 내의 메모리를 공유하기 때문에 데이터 전달이 간단하므로 IPC에 비해 비용이 적고 더 빠르다. ⇒ 스레드는 프로세스의 stack영역을 제외한 모든 메모리를 공유하기 때문

### PC 레지스터를 스레드마다 독립적으로 할당하는 이유?

PC값은 스레드가 명령어의  어디까지 수행했는지를 나타내게 된다. 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다.

### 스택을 스레드마다 독립적으로 할당하는 이유는?

스택은 함수 호출 시 전달되는 인자, 복귀 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이다.

스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능함을 의미하고 이는 독립적인 실행 흐름이 추가된다는 것이다. 따라서 쓰레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당하는 것이다.

[https://wooody92.github.io/os/멀티-프로세스와-멀티-스레드/](https://wooody92.github.io/os/%EB%A9%80%ED%8B%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EB%A9%80%ED%8B%B0-%EC%8A%A4%EB%A0%88%EB%93%9C/)

# 사용자 수준 스레드와 커널 수준 스레드

### 사용자 수준 스레드

- 스레드 교환에 커널이 개입하지 않는다.
- 스레드와 관련된 행위를 유저쪽에서 한다.
- 장점
    - 스레드 전환 시 커널 스케줄러를 호출할 필요가 없기 때문에 사용자 수준 스레드는 내용 전환이 비교적 적다. 따라서 커널 수준 스레드보다 오버헤드가 작다.
    - 스레드 스케줄러가 사용자 모드에만 존재한다.
- 단점
    - **프로세스 내의 한 스레드가 (I/O 요청)커널로 진입하는 순간 나머지 스레드는 전부 정지된다.**
    - 이는 커널이 스레드의 존재를 알지 못하기 때문에 발생하는 현상

### 커널 수준 스레드

- 장점
    - 사용자 수준 스레드보다 효율적이다. 커널 스레드를 쓰면 멀티프로세서를 활용할 수 있는 장점이 있다.
    - 사용자 스레드는 CPU가 아무리 많더라도 커널 모드의 스케줄이 되지 않으므로 각 CPU에 효율적으로 스레드를 배당할 수 없다
- 단점
    - 커널 스케줄러를 통해 내용 전환이 발생한다. 이 과정에서 프로세서 모드가 사용자 모드와 커널 모드 사이를 움직이기 때문에 빈번할 수록 성능이 하락한다.

# 동기화

**공유 자원에 대하여 동시에 접근하는 프로세스/스레드들로 인해 발생하는 문제를 해결하기 위해 행하는 방식**

- 경쟁상태: 경쟁상태란 두 개 이상의 프로세스 혹은 스레드가 공유 자원을 동시에 사용할 때 그 순서에 따라 결과가 달라지는 문제. 은행 잔고를 예로 들면 은행 잔고라는 공유 데이터를 읽어와서 입금연산과 출금연산을 하는데, 동시에 접근해서 연산해버리면 한 쪽 연산이 반영이 안되는 문제
- 임계 영역: 프로세스 간에 공유 자원을 접근하는데 있어서 문제가 발생하지 않도록 한번에 하나의 프로세스만 이용하게끔 보장해줘야 하는 영역
- 임계영역과 크리티컬 섹션: 사전상으로는 같은 말이지만 의미하는 바가 다를 수 있다. 임계영역은 프로세스간 자원이 공유될 수 있는 코드 블록을 의미하며, 크리티컬 섹션은 하나의 동기화 방법을 말한다. 임계영역 문제를 해결하기 위해서는 3가지 조건을 충족해야한다.
    - 상호 배제: 프로세스가 크리티컬 섹션에 들어가 있다면 , 다른 프로세스는 크리티컬 섹션에 들어갈 수 없다.
    - 진행: 크리티컬 섹션에 들어가 있는 프로세스가 없다면 다른 후보 프로세스가 진입할 수 있어야 한다.
    - 한정 대기: 다른 프로세스의 기아를 방지하기 위해 한번 임계 구역에 들어간 프로세스는 다음 번 임계영역을 들어갈 때 제한을 두어야 한다.
- 임계 영역의 동시 접근을 해결하기 위한 방법으로는 락, 세마포어, 모니터 등이 있다.

### 락

- 하나의 스레드나 프로세스가 자원을 사용하고 있는 동안에는 잠궈서 접근을 못하게 하는 방식
- A 스레드가 공유자원 락을 걸고 사용하는 동안 라운드 로빈 스케줄링에 의해 timer Interrupt가 걸렸다고 가정하고 B 스레드가 수행이 되면 B 스레드가 공유자원을 접근하려 할 때 락이 걸려있으면 해제해주기를 기다리게 된다(busy-waits), 그리고 다시 A 스레드가 스케줄링에 의해 나머지를 다 수행하고 락을 해제하게 되면 그제서야 B 스레드가 수행되는 것이 락의 방식이다.
- 락은 변수(bool 값)을 통한 무한루프문을 통해 구현할 수 있다. 해제 해주기를 기다리는 부분이 이 무한루프에서 빠져나오지 못하기 때문이다. 이처럼 의미없는 코드를 반복 수행하며 기다리는 것을 busy-waits라 한다.
- 락의 문제점: 특정한 상황에서 제대로 작동하지 않는 문제가 있다.
- 락의 해결방법
    - 소프트웨어 알고리즘(ex 피터슨 알고리즘) ⇒느려서 사용하지 않는다.
    - 더 이상 쪼개지지 않는 하드웨어 명령어로 구현하는 방법
    - 인터럽트를 disable하고 enable하는 방법

### 뮤텍스

- 0과 1을 가진 이진 세마포어와 유사하다.
- 다른 프로세스간의 동기화를 할 때 사용한다.
- 임계 영역을 가진 스레드들의 실행시간을 서로 겹치지 않게 하나의 프로세스나 스레드를 단독으로 실행하게 한다.(락을 사용)
- 락을 획득한 프로세스가 반드시 그 락을 해제해야한다.

### 뮤텍스와 락의 차이점

락과 뮤텍스는 임계영역의 락이 풀릴때까지 기다려야 한다는 점은 같지만 락은 락이 걸려 있을 경우 이를 얻을 때까지 무한루프를 돌면서 CPU를 양보하지 않게 된다.

반면 뮤텍스는 락이 걸려 있을 경우 락이 풀릴 때까지 기다리며 컨텍스트 스위칭을 실행한다. 병력적인 처리를 하기 위해 CPU를 양보할 수 있어 자원을 얻기 위해 오랜 시간이 걸릴 경우 다른 작업을 동시에 진행할 수 있지만 자원이 단시간 내로 얻어지는 경우 컨텍스트 스위칭이 더 큰 자원을 낭비하게 될 수 있는 문제가 있다.

### 세마포어

- 세마포어는 이진 세마포어와 카운팅 세마포어가 있다.
- 카운팅 세마포어는 정수 값을 가지는 변수로 볼 수 있으며, 정수 값은 접근할 수 있는 최대 허용치이다.
- 하나 또는 여러개의 프로세스나 스레드가 자원에 접근 가능하다.
- 현재 수행중인 프로세스가 아닌 다른 프로세스가 세마포어를 해제할 수 있다.

### 모니터

- 한 프로세스 내에 있는 하나의 스레드만 자원에 접근 가능하다.(하나의 프로세스 안에 다른 스레드간 동기화를 할 때 사용한다.)
- 모니터는 개념적으로 이진 세마포어만 가능하다.

[https://hombody.tistory.com/240](https://hombody.tistory.com/240)

# 세마포어와 뮤텍스란? 차이점?

### 세마포어와 뮤텍스의 정의

- 여러 프로세스나 쓰레드가 **공유 자원에 접근하는 것을 제어하기 위한 방법**
- **병행 처리를 위한 프로세스 동기화 기법**

### 세마포어

- 세마포어 변수, wait()함수, signal()함수가 있다.
- 세파포어 변수: 공유 가능한 자원의 수
- wait(): 세마포어 값을 감소시킨다. 음수가 되면 호출한 프로세스는 블록된다.
- signal(): 실행되던 프로세스가 종료되어, 세마포어 값을 증가시킨다. 만약 값이 0이거나 음수면 semWait 연산에 의해 블록된 프로세스를 wake_up한다.
- 세마포어 종류: binary 세마포어(세마포어가 0또는 1만 허용 ⇒ 뮤텍스와 비슷), counting 세마포어(0 또는 1 이상의 수를 가질 수 있다.)

### 뮤텍스

- 초기값을 1과 0으로 가진다.
- 임계구역에 들어갈 때 락을 걸어 다른 프로세스(또는 쓰레드))가 접근하지 못하도록 하고 임계구역에서 나올 때 해당 락을 해제한다.

### 뮤텍스와 세마포어의 차이

- 세마포어는 공유 자원에 세마포어의 변수만큼 프로세스(또는 쓰레드)가 접근할 수 있다. 반면에 뮤텍스는 오직 1개의 프로세스(또는 쓰레드)만 접근 가능
- 현재 수행중인 프로세스가 아닌 다른 프로세스가 세마포어를 해제할 수 있다. 하지만 뮤텍스는 락을 획득한 프로세스가 반드시 그 락을 해제해야 한다.

[https://velog.io/@conatuseus/OS-세마포어와-뮤텍스](https://velog.io/@conatuseus/OS-%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4%EC%99%80-%EB%AE%A4%ED%85%8D%EC%8A%A4)

# 멀티 프로세싱, 멀티 프로그래밍, 멀티 스레딩, 멀티 태스킹

- CPU 코어의 관점에서 생각

### 멀티 프로세싱

- CPU N개, 프로세스 N 수행(멀티 프로세스X, 멀티 프로세서)

### 멀티 쓰레딩

- CPU 1, 쓰레드 N 수행

### 멀티 프로그래밍

- CPU 1, 프로세스 N 수행
- 프로세스 A에 대해서 프로세서가 작업(ec I/O 작업)을 처리할 때 낭비되는 시간동안 다른 프로세스를 처리하도록 하는 것.
- **CPU의 자원이 낭비되는 것을 최소화**

### 멀티 태스킹

- 다수의 TASK(프로세스보다 조금 더 확장된 개녕)를 운영체제의 스케줄링에 의해 번갈아가면서 수행하는 것
- **일정하게 정해진 시간동안 번갈아가면서 각각의 TASK를 처리하는 것**

# 동기, 비동기, 블로킹, 넌블로킹

### 동기

- 어떤 일에 대한 요청과 응답이 동시에 이루어져야 하는 것
- Call하고 응답이 올때까지 기다렸다가 다음 로직을 실행한다.
- 장점: 안정성이 보장된다, 순서가 보장된다
- 단점: 느리다

### 비동기

- 어떤 일에 대한 요청과 응답이 동시에 이루어질 필요없이 따로 이루어지는 것
- Call하고 응답이 오지 않아도 다음 로직을 실행한다.
- 장점: 빠르다
- 단점: 처리하기가 까다롭다. 순서가 보장되지 않는다.

### 블로킹

- 어떤 요청에 대한 응답이 올때까지 대기 하는 것
- 즉, 동기를 위해서는 블로킹 되어야한다

### 넌블로킹

- 어떤 요청에 대해서 응답을 대기하지 않고 계속 루틴을 수행하는 것
- 비동기를 위해서는 넌블로킹 되어야 하지만, 넌블로킹이 비동기는 아니다.(포함관계)
- 예를들어 넌블로킹이면서 요청에 대한 응답을 계속해서 요구하는 폴링 방식의 경우 비동기라고 하기는 힘들다.
- 이벤트 핸들러나 인터럽트를 통해 응답을 받는 것이 비동기 모델